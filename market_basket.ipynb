{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7d5b9a",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a61084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'file_path.csv' with the actual path to your CSV file\n",
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MYMARKET/cleaned_merged_data2.csv'\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 10000  # You can adjust this based on your requirements\n",
    "\n",
    "# Create an empty list to store the individual DataFrames\n",
    "chunk_dfs = []\n",
    "\n",
    "# Create an iterator to read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk and store them in the list\n",
    "for chunk in chunk_iterator:\n",
    "    #  appending each chunk to the list\n",
    "    chunk_dfs.append(chunk)\n",
    "\n",
    "# Concatenate all the chunks into a single DataFrame\n",
    "full_df = pd.concat(chunk_dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc66c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine columns using underscores\n",
    "full_df['COMBINED'] = full_df['ITH_SECTION_CODE'].astype(str)+ '_' + full_df['ITH_DEPT_CODE'].astype(str) + '_' + full_df['ITH_CATEG_CODE'].astype(str)+ '_' + full_df['ITH_GROUP_CODE'].astype(str)\n",
    "\n",
    "# View the updated DataFrame with the combined column\n",
    "print(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eaed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['ITH_DEPT_CODE', 'ITH_CATEG_CODE','ITH_SECTION_CODE','ITH_GROUP_CODE', 'ITH_SUBGROUP_CODE','Combined']\n",
    "\n",
    "# Dropping multiple columns\n",
    "full_df.drop(columns=columns_to_drop, inplace=True)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = full_df['TRANSACTION_ID'].value_counts()\n",
    "\n",
    "# Filter out rows with unique TRANSACTION_IDs\n",
    "full_df = full_df[full_df['TRANSACTION_ID'].isin(counts.index[counts > 1])]\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39612f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_size = 100000  # Set the chunk size according to your system's memory capacity\n",
    "\n",
    "# Open the CSV file in write mode with UTF-8 encoding\n",
    "with open('clean_wrangle_data3.csv', 'w', encoding='utf-8') as f:\n",
    "    for i in range(0, len(full_df), chunk_size):\n",
    "        full_df.iloc[i:i+chunk_size].to_csv(f, index=False, header=not f.tell(), encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b344cfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3286e5dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m chunk_iterator \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, chunksize\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Process each chunk and store them in the list\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_iterator:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#  appending each chunk to the list\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     chunk_dfs\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Concatenate all the chunks into a single DataFrame\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1624\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1623\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1624\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_chunk()\n\u001b[0;32m   1625\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1626\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1733\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1731\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[1;32m-> 1733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nrows\u001b[38;5;241m=\u001b[39msize)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:826\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1036\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1090\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1165\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[0;32m   1332\u001b[0m     )\n\u001b[1;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'file_path.csv' with the actual path to your CSV file\n",
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MYMARKET/clean_wrangle_data3.csv'\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 10000  # You can adjust this based on your requirements\n",
    "\n",
    "# Create an empty list to store the individual DataFrames\n",
    "chunk_dfs = []\n",
    "\n",
    "# Create an iterator to read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk and store them in the list\n",
    "for chunk in chunk_iterator:\n",
    "    #  appending each chunk to the list\n",
    "    chunk_dfs.append(chunk)\n",
    "\n",
    "# Concatenate all the chunks into a single DataFrame\n",
    "full_df = pd.concat(chunk_dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(full_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c6ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace '2e6' with the number of rows you want to sample\n",
    "sample_size = 108000000\n",
    "\n",
    "# Randomly sample 110 million rows from the DataFrame\n",
    "sampled_df = full_df.sample(n=sample_size, random_state=42)  # Use any random_state for reproducibility\n",
    "\n",
    "# Display information about the sampled DataFrame\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2d437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = sampled_df['TRANSACTION_ID'].value_counts()\n",
    "\n",
    "# Filter out rows with unique TRANSACTION_IDs\n",
    "sampled_df = sampled_df[sampled_df['TRANSACTION_ID'].isin(counts.index[counts > 1])]\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fd0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "chunk_size = 100000  # Set the chunk size according to your system's memory capacity\n",
    "\n",
    "# Open the CSV file in write mode with UTF-8 encoding\n",
    "with open('sampled_cleaned_wrangled_data3.csv', 'w', encoding='utf-8') as f:\n",
    "    for i in range(0, len(sampled_df), chunk_size):\n",
    "        sampled_df.iloc[i:i+chunk_size].to_csv(f, index=False, header=not f.tell(), encoding='utf-8')\n",
    "\n",
    "\n",
    "# Assuming 'sampled_df' is the DataFrame you want to write to a CSV file\n",
    "# Replace 'file_name.csv' with the desired name for your CSV file\n",
    "#file_name = 'sampled_cleaned_wrangled_data3.csv'\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "#sampled_df.to_csv(file_name, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50aab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Market analysis PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f4f38f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>ITEM_SK</th>\n",
       "      <th>TYPE_SK</th>\n",
       "      <th>ITH_SK</th>\n",
       "      <th>COMBINED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353954392</td>\n",
       "      <td>11015</td>\n",
       "      <td>6</td>\n",
       "      <td>3447</td>\n",
       "      <td>11_1_12_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366793053</td>\n",
       "      <td>114161</td>\n",
       "      <td>6</td>\n",
       "      <td>21368</td>\n",
       "      <td>49_15_5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354954901</td>\n",
       "      <td>16010</td>\n",
       "      <td>6</td>\n",
       "      <td>4510</td>\n",
       "      <td>15_1_16_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365055773</td>\n",
       "      <td>22922</td>\n",
       "      <td>6</td>\n",
       "      <td>15013</td>\n",
       "      <td>31_1_1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359244309</td>\n",
       "      <td>111533</td>\n",
       "      <td>6</td>\n",
       "      <td>29051</td>\n",
       "      <td>81_31_1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997629</th>\n",
       "      <td>371167841</td>\n",
       "      <td>40481</td>\n",
       "      <td>6</td>\n",
       "      <td>24080</td>\n",
       "      <td>56_1_2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997630</th>\n",
       "      <td>355245131</td>\n",
       "      <td>113008</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>1_1_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997631</th>\n",
       "      <td>367545291</td>\n",
       "      <td>53226</td>\n",
       "      <td>5</td>\n",
       "      <td>27990</td>\n",
       "      <td>77_6_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997632</th>\n",
       "      <td>368861322</td>\n",
       "      <td>39142</td>\n",
       "      <td>6</td>\n",
       "      <td>22025</td>\n",
       "      <td>51_1_10_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997633</th>\n",
       "      <td>364991428</td>\n",
       "      <td>22892</td>\n",
       "      <td>6</td>\n",
       "      <td>15001</td>\n",
       "      <td>31_1_1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107997634 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TRANSACTION_ID  ITEM_SK  TYPE_SK  ITH_SK    COMBINED\n",
       "0               353954392    11015        6    3447   11_1_12_2\n",
       "1               366793053   114161        6   21368   49_15_5_1\n",
       "2               354954901    16010        6    4510   15_1_16_1\n",
       "3               365055773    22922        6   15013   31_1_1_11\n",
       "4               359244309   111533        6   29051  81_31_1_12\n",
       "...                   ...      ...      ...     ...         ...\n",
       "107997629       371167841    40481        6   24080    56_1_2_1\n",
       "107997630       355245131   113008        6      67     1_1_5_2\n",
       "107997631       367545291    53226        5   27990    77_6_5_2\n",
       "107997632       368861322    39142        6   22025   51_1_10_4\n",
       "107997633       364991428    22892        6   15001    31_1_1_1\n",
       "\n",
       "[107997634 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'file_path.csv' with the actual path to your CSV file\n",
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MyMarket2/sampled_cleaned_wrangled_data3.csv'\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 10000  # You can adjust this based on your requirements\n",
    "\n",
    "# Create an empty list to store the individual DataFrames\n",
    "chunk_dfs = []\n",
    "\n",
    "# Create an iterator to read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk and store them in the list\n",
    "for chunk in chunk_iterator:\n",
    "    #  appending each chunk to the list\n",
    "    chunk_dfs.append(chunk)\n",
    "\n",
    "# Concatenate all the chunks into a single DataFrame\n",
    "sampled_df = pd.concat(chunk_dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394ff92",
   "metadata": {},
   "source": [
    "# hotencode for mba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb30b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>COMBINED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353954392</td>\n",
       "      <td>11_1_12_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366793053</td>\n",
       "      <td>49_15_5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354954901</td>\n",
       "      <td>15_1_16_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365055773</td>\n",
       "      <td>31_1_1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359244309</td>\n",
       "      <td>81_31_1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997629</th>\n",
       "      <td>371167841</td>\n",
       "      <td>56_1_2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997630</th>\n",
       "      <td>355245131</td>\n",
       "      <td>1_1_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997631</th>\n",
       "      <td>367545291</td>\n",
       "      <td>77_6_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997632</th>\n",
       "      <td>368861322</td>\n",
       "      <td>51_1_10_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997633</th>\n",
       "      <td>364991428</td>\n",
       "      <td>31_1_1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107997634 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TRANSACTION_ID    COMBINED\n",
       "0               353954392   11_1_12_2\n",
       "1               366793053   49_15_5_1\n",
       "2               354954901   15_1_16_1\n",
       "3               365055773   31_1_1_11\n",
       "4               359244309  81_31_1_12\n",
       "...                   ...         ...\n",
       "107997629       371167841    56_1_2_1\n",
       "107997630       355245131     1_1_5_2\n",
       "107997631       367545291    77_6_5_2\n",
       "107997632       368861322   51_1_10_4\n",
       "107997633       364991428    31_1_1_1\n",
       "\n",
       "[107997634 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming sampled_df is your DataFrame\n",
    "columns_to_drop = ['ITEM_SK', 'TYPE_SK', 'ITH_SK']  # Replace these with the actual column names you want to drop\n",
    "\n",
    "# Dropping columns directly in the DataFrame\n",
    "sampled_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Iterating through rows and dropping rows where 'COMBINED' column is equal to \"50_7_1_1\"\n",
    "#indexes_to_drop = []  # Store indexes to drop\n",
    "\n",
    "#for index, row in sampled_df.iterrows():\n",
    "#    if row['COMBINED'] == \"50_7_1_1\":\n",
    "#        indexes_to_drop.append(index)\n",
    "\n",
    "#sampled_df.drop(indexes_to_drop, inplace=True)\n",
    "\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c3d6222-ee86-461d-8a7c-f072c6d32eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>COMBINED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353954392</td>\n",
       "      <td>11_1_12_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366793053</td>\n",
       "      <td>49_15_5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354954901</td>\n",
       "      <td>15_1_16_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365055773</td>\n",
       "      <td>31_1_1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359244309</td>\n",
       "      <td>81_31_1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997629</th>\n",
       "      <td>371167841</td>\n",
       "      <td>56_1_2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997630</th>\n",
       "      <td>355245131</td>\n",
       "      <td>1_1_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997631</th>\n",
       "      <td>367545291</td>\n",
       "      <td>77_6_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997632</th>\n",
       "      <td>368861322</td>\n",
       "      <td>51_1_10_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997633</th>\n",
       "      <td>364991428</td>\n",
       "      <td>31_1_1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102155837 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TRANSACTION_ID    COMBINED\n",
       "0               353954392   11_1_12_2\n",
       "1               366793053   49_15_5_1\n",
       "2               354954901   15_1_16_1\n",
       "3               365055773   31_1_1_11\n",
       "4               359244309  81_31_1_12\n",
       "...                   ...         ...\n",
       "107997629       371167841    56_1_2_1\n",
       "107997630       355245131     1_1_5_2\n",
       "107997631       367545291    77_6_5_2\n",
       "107997632       368861322   51_1_10_4\n",
       "107997633       364991428    31_1_1_1\n",
       "\n",
       "[102155837 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df = sampled_df[sampled_df['COMBINED'] != \"70_5_1_1\"]\n",
    "sampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1c3e48",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>COMBINED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353954392</td>\n",
       "      <td>11_1_12_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366793053</td>\n",
       "      <td>49_15_5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354954901</td>\n",
       "      <td>15_1_16_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365055773</td>\n",
       "      <td>31_1_1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359244309</td>\n",
       "      <td>81_31_1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997629</th>\n",
       "      <td>371167841</td>\n",
       "      <td>56_1_2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997630</th>\n",
       "      <td>355245131</td>\n",
       "      <td>1_1_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997631</th>\n",
       "      <td>367545291</td>\n",
       "      <td>77_6_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997632</th>\n",
       "      <td>368861322</td>\n",
       "      <td>51_1_10_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997633</th>\n",
       "      <td>364991428</td>\n",
       "      <td>31_1_1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102155717 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TRANSACTION_ID    COMBINED\n",
       "0               353954392   11_1_12_2\n",
       "1               366793053   49_15_5_1\n",
       "2               354954901   15_1_16_1\n",
       "3               365055773   31_1_1_11\n",
       "4               359244309  81_31_1_12\n",
       "...                   ...         ...\n",
       "107997629       371167841    56_1_2_1\n",
       "107997630       355245131     1_1_5_2\n",
       "107997631       367545291    77_6_5_2\n",
       "107997632       368861322   51_1_10_4\n",
       "107997633       364991428    31_1_1_1\n",
       "\n",
       "[102155717 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences of each category in the 'COMBINED' column\n",
    "category_counts = sampled_df['COMBINED'].value_counts()\n",
    "\n",
    "# Find categories that appear only once\n",
    "single_occurrence_categories = category_counts[category_counts == 1].index\n",
    "\n",
    "# Filter the DataFrame to exclude rows with these categories\n",
    "filtered_df = sampled_df[~sampled_df['COMBINED'].isin(single_occurrence_categories)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6353bc63",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'COMBINED' column: 1606\n"
     ]
    }
   ],
   "source": [
    "unique_combined_values = filtered_df['COMBINED'].nunique()\n",
    "print(f\"Number of unique values in 'COMBINED' column: {unique_combined_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e0d7378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lazaros.Sofikitis\\AppData\\Local\\Temp\\ipykernel_10592\\2372531538.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['COMBINED'] = filtered_df['COMBINED'].apply(modify_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TRANSACTION_ID COMBINED\n",
      "0               353954392  11_1_12\n",
      "1               366793053  49_15_5\n",
      "2               354954901  15_1_16\n",
      "3               365055773   31_1_1\n",
      "4               359244309  81_31_1\n",
      "...                   ...      ...\n",
      "107997629       371167841   56_1_2\n",
      "107997630       355245131    1_1_5\n",
      "107997631       367545291   77_6_5\n",
      "107997632       368861322  51_1_10\n",
      "107997633       364991428   31_1_1\n",
      "\n",
      "[102155717 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def modify_string(s):\n",
    "    parts = s.split('_')\n",
    "    modified_string = '_'.join(parts[:3])\n",
    "    return modified_string\n",
    "\n",
    "# Replace existing column values with modified strings\n",
    "filtered_df['COMBINED'] = filtered_df['COMBINED'].apply(modify_string)\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc83237",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "           TRANSACTION_ID    COMBINED       ID\n",
      "0               353954392   11_1_12_2        1\n",
      "1               366793053   49_15_5_1        2\n",
      "2               354954901   15_1_16_1        3\n",
      "3               365055773   31_1_1_11        4\n",
      "4               359244309  81_31_1_12        5\n",
      "...                   ...         ...      ...\n",
      "102155832       371167841    56_1_2_1  9070555\n",
      "102155833       355245131     1_1_5_2  2165030\n",
      "102155834       367545291    77_6_5_2  3462352\n",
      "102155835       368861322   51_1_10_4  1391805\n",
      "102155836       364991428    31_1_1_1  2065723\n",
      "\n",
      "[102155837 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assign an incrementing ID for each distinct value\n",
    "unique_values = filtered_df['TRANSACTION_ID'].unique()\n",
    "value_to_id = {val: idx + 1 for idx, val in enumerate(unique_values)}\n",
    "\n",
    "filtered_df['ID'] = filtered_df['TRANSACTION_ID'].map(value_to_id)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21deb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_size = 100000  # Set the chunk size according to your system's memory capacity\n",
    "\n",
    "# Open the CSV file in write mode with UTF-8 encoding\n",
    "with open('filtered_df_for_matrix.csv', 'w', encoding='utf-8') as f:\n",
    "    for i in range(0, len(filtered_df), chunk_size):\n",
    "        filtered_df.iloc[i:i+chunk_size].to_csv(f, index=False, header=not f.tell(), encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ffc1d",
   "metadata": {},
   "source": [
    "# sparse matrix creation(cost intensive operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922994e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>COMBINED</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353954392</td>\n",
       "      <td>11_1_12_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366793053</td>\n",
       "      <td>49_15_5_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354954901</td>\n",
       "      <td>15_1_16_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365055773</td>\n",
       "      <td>31_1_1_11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359244309</td>\n",
       "      <td>81_31_1_12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102155832</th>\n",
       "      <td>371167841</td>\n",
       "      <td>56_1_2_1</td>\n",
       "      <td>9070555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102155833</th>\n",
       "      <td>355245131</td>\n",
       "      <td>1_1_5_2</td>\n",
       "      <td>2165030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102155834</th>\n",
       "      <td>367545291</td>\n",
       "      <td>77_6_5_2</td>\n",
       "      <td>3462352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102155835</th>\n",
       "      <td>368861322</td>\n",
       "      <td>51_1_10_4</td>\n",
       "      <td>1391805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102155836</th>\n",
       "      <td>364991428</td>\n",
       "      <td>31_1_1_1</td>\n",
       "      <td>2065723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102155837 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TRANSACTION_ID    COMBINED       ID\n",
       "0               353954392   11_1_12_2        1\n",
       "1               366793053   49_15_5_1        2\n",
       "2               354954901   15_1_16_1        3\n",
       "3               365055773   31_1_1_11        4\n",
       "4               359244309  81_31_1_12        5\n",
       "...                   ...         ...      ...\n",
       "102155832       371167841    56_1_2_1  9070555\n",
       "102155833       355245131     1_1_5_2  2165030\n",
       "102155834       367545291    77_6_5_2  3462352\n",
       "102155835       368861322   51_1_10_4  1391805\n",
       "102155836       364991428    31_1_1_1  2065723\n",
       "\n",
       "[102155837 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Replace 'file_path.csv' with the actual path to your CSV file\n",
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MyMarket2/filtered_df_for_matrix.csv'\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 10000  # You can adjust this based on your requirements\n",
    "\n",
    "# Create an empty list to store the individual DataFrames\n",
    "chunk_dfs = []\n",
    "\n",
    "# Create an iterator to read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk and store them in the list\n",
    "for chunk in chunk_iterator:\n",
    "    #  appending each chunk to the list\n",
    "    chunk_dfs.append(chunk)\n",
    "\n",
    "# Concatenate all the chunks into a single DataFrame\n",
    "filtered_df = pd.concat(chunk_dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################CHUNK SIZE SPARSE MATRIX###############################################\n",
    "################################################FOR TOO BIG FILES##################################################\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file in chunks if it's too large to fit in memory at once\n",
    "chunk_size = 100000  # Adjust the chunk size as needed\n",
    "product_to_col = {}\n",
    "data = []\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "transaction_counter = 0\n",
    "\n",
    "# Loop through chunks of the file\n",
    "for chunk in pd.read_csv('C:/Users/Lazaros.Sofikitis/Desktop/MyMarket2/filtered_df_for_matrix.csv', chunksize=chunk_size):\n",
    "    for index, row in chunk.iterrows():\n",
    "        transaction_id = row['ID']\n",
    "        product_id = row['COMBINED']\n",
    "        \n",
    "        # Mapping product IDs to column indices\n",
    "        if product_id not in product_to_col:\n",
    "            product_to_col[product_id] = len(product_to_col)\n",
    "        \n",
    "        row_indices.append(transaction_counter)\n",
    "        col_indices.append(product_to_col[product_id])\n",
    "        data.append(1)\n",
    "        \n",
    "        transaction_counter += 1\n",
    "\n",
    "# Create the sparse matrix directly\n",
    "sparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(transaction_counter, len(product_to_col)))\n",
    "\n",
    "print(sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc71e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 78)\t1\n",
      "  (0, 652)\t1\n",
      "  (0, 702)\t1\n",
      "  (0, 1008)\t1\n",
      "  (0, 3261)\t1\n",
      "  (0, 3306)\t1\n",
      "  (1, 314)\t1\n",
      "  (1, 323)\t1\n",
      "  (1, 344)\t1\n",
      "  (1, 365)\t1\n",
      "  (1, 372)\t1\n",
      "  (1, 427)\t1\n",
      "  (1, 429)\t1\n",
      "  (1, 433)\t1\n",
      "  (1, 439)\t1\n",
      "  (1, 444)\t2\n",
      "  (1, 577)\t1\n",
      "  (1, 702)\t1\n",
      "  (1, 790)\t1\n",
      "  (1, 1138)\t1\n",
      "  (1, 1277)\t1\n",
      "  (1, 1305)\t1\n",
      "  (1, 1383)\t1\n",
      "  (1, 1512)\t1\n",
      "  (1, 1618)\t1\n",
      "  :\t:\n",
      "  (12071847, 2507)\t1\n",
      "  (12071848, 1301)\t1\n",
      "  (12071849, 4437)\t1\n",
      "  (12071850, 1155)\t1\n",
      "  (12071851, 2203)\t1\n",
      "  (12071852, 1691)\t1\n",
      "  (12071853, 387)\t1\n",
      "  (12071854, 2773)\t1\n",
      "  (12071855, 577)\t1\n",
      "  (12071856, 2867)\t1\n",
      "  (12071857, 2803)\t1\n",
      "  (12071858, 2793)\t1\n",
      "  (12071859, 2848)\t1\n",
      "  (12071860, 2431)\t1\n",
      "  (12071861, 130)\t1\n",
      "  (12071862, 1251)\t1\n",
      "  (12071863, 2627)\t1\n",
      "  (12071864, 3659)\t1\n",
      "  (12071865, 2229)\t1\n",
      "  (12071866, 625)\t1\n",
      "  (12071867, 2424)\t1\n",
      "  (12071868, 365)\t1\n",
      "  (12071869, 628)\t1\n",
      "  (12071870, 2424)\t1\n",
      "  (12071871, 4447)\t1\n"
     ]
    }
   ],
   "source": [
    "####################################################SPARSE MATRIX CREATOR############################################\n",
    "####################################################IF DF IS ALREADY LOADED#######################################\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create an enumeration for products\n",
    "product_ids = filtered_df['COMBINED'].unique()\n",
    "product_ids.sort()  # Ensure consistent order\n",
    "\n",
    "# Create a dictionary to map product IDs to column indices\n",
    "product_to_col = {product_id: i for i, product_id in enumerate(product_ids)}\n",
    "\n",
    "# Create lists to store row, column, and data indices for the sparse matrix\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "data = []\n",
    "\n",
    "# Loop through each transaction and update the lists\n",
    "for _, row in filtered_df.iterrows():\n",
    "    transaction_id = row['ID']\n",
    "    product_id = row['COMBINED']\n",
    "    \n",
    "    row_indices.append(transaction_id - 1)  # Subtract 1 to start from index 0\n",
    "    col_indices.append(product_to_col[product_id])\n",
    "    data.append(1)  # Use 1 to indicate presence of product\n",
    "\n",
    "# Create the sparse matrix using the COO format\n",
    "sparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(max(row_indices) + 1, len(product_ids)))\n",
    "\n",
    "#############30 minutes####################################\n",
    "\n",
    "# Display the sparse matrix\n",
    "print(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2cc79b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz, load_npz\n",
    "\n",
    "# Save a sparse matrix\n",
    "save_npz('sparse_matrix.npz', sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44382484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz, load_npz\n",
    "sparse_matrix = load_npz('sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Count values greater than 1\n",
    "count_greater_than_one = (sparse_matrix.data > 1).sum()\n",
    "\n",
    "print(\"Number of values greater than 1 in the sparse matrix:\", count_greater_than_one)\n",
    "\n",
    "\n",
    "# Get the number of non-zero elements in the sparse matrix\n",
    "num_non_zero_elements = sparse_matrix.nnz\n",
    "\n",
    "print(\"Number of non-zero elements in the sparse matrix:\", num_non_zero_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a969f84a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4457</th>\n",
       "      <th>4458</th>\n",
       "      <th>4459</th>\n",
       "      <th>4460</th>\n",
       "      <th>4461</th>\n",
       "      <th>4462</th>\n",
       "      <th>4463</th>\n",
       "      <th>4464</th>\n",
       "      <th>4465</th>\n",
       "      <th>4466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12071867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12071868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12071869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12071870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12071871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12071872 rows × 4467 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "0            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "1            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "2            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "3            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "4            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "12071867     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "12071868     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "12071869     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "12071870     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "12071871     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "          4457  4458  4459  4460  4461  4462  4463  4464  4465  4466  \n",
       "0            0     0     0     0     0     0     0     0     0     0  \n",
       "1            0     0     0     0     0     0     0     0     0     0  \n",
       "2            0     0     0     0     0     0     0     0     0     0  \n",
       "3            0     0     0     0     0     0     0     0     0     0  \n",
       "4            0     0     0     0     0     0     0     0     0     0  \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "12071867     0     0     0     0     0     0     0     0     0     0  \n",
       "12071868     0     0     0     0     0     0     0     0     0     0  \n",
       "12071869     0     0     0     0     0     0     0     0     0     0  \n",
       "12071870     0     0     0     0     0     0     0     0     0     0  \n",
       "12071871     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[12071872 rows x 4467 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_df = pd.DataFrame.sparse.from_spmatrix(sparse_matrix)\n",
    "# Assuming you have a DataFrame 'df' representing the sparse matrix\n",
    "sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab63785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count cells where the value is greater than 1\n",
    "count_greater_than_one = (sparse_df > 1).sum().sum()\n",
    "print(\"Number of cells where value = 1:\", count_greater_than_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f99a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert to boolean (True/False) indicating presence or absence of items\n",
    "sparse_df_boolean = sparse_df > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c133b80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1      2      3      4      5      6      7      8     \\\n",
      "0         False  False  False  False  False  False  False  False  False   \n",
      "1         False  False  False  False  False  False  False  False  False   \n",
      "2         False  False  False  False  False  False  False  False  False   \n",
      "3         False  False  False  False  False  False  False  False  False   \n",
      "4         False  False  False  False  False  False  False  False  False   \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "12071867  False  False  False  False  False  False  False  False  False   \n",
      "12071868  False  False  False  False  False  False  False  False  False   \n",
      "12071869  False  False  False  False  False  False  False  False  False   \n",
      "12071870  False  False  False  False  False  False  False  False  False   \n",
      "12071871  False  False  False  False  False  False  False  False  False   \n",
      "\n",
      "           9     ...   4457   4458   4459   4460   4461   4462   4463   4464  \\\n",
      "0         False  ...  False  False  False  False  False  False  False  False   \n",
      "1         False  ...  False  False  False  False  False  False  False  False   \n",
      "2         False  ...  False  False  False  False  False  False  False  False   \n",
      "3         False  ...  False  False  False  False  False  False  False  False   \n",
      "4         False  ...  False  False  False  False  False  False  False  False   \n",
      "...         ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "12071867  False  ...  False  False  False  False  False  False  False  False   \n",
      "12071868  False  ...  False  False  False  False  False  False  False  False   \n",
      "12071869  False  ...  False  False  False  False  False  False  False  False   \n",
      "12071870  False  ...  False  False  False  False  False  False  False  False   \n",
      "12071871  False  ...  False  False  False  False  False  False  False  False   \n",
      "\n",
      "           4465   4466  \n",
      "0         False  False  \n",
      "1         False  False  \n",
      "2         False  False  \n",
      "3         False  False  \n",
      "4         False  False  \n",
      "...         ...    ...  \n",
      "12071867  False  False  \n",
      "12071868  False  False  \n",
      "12071869  False  False  \n",
      "12071870  False  False  \n",
      "12071871  False  False  \n",
      "\n",
      "[12071872 rows x 4467 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sparse_df_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a15df26-cb53-4c7f-80fd-e0399db10809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 100000  # Set the chunk size according to your system's memory capacity\n",
    "\n",
    "# Open the CSV file in write mode with UTF-8 encoding\n",
    "with open('sparse_df_boolean.csv', 'w', encoding='utf-8') as f:\n",
    "    for i in range(0, len(sparse_df_boolean), chunk_size):\n",
    "        sparse_df_boolean.iloc[i:i+chunk_size].to_csv(f, index=False, header=not f.tell(), encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a5883-338e-4da0-8939-3087994a24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MyMarket2/sparse_df_boolean.csv'\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 10000  # You can adjust this based on your requirements\n",
    "\n",
    "# Create an empty list to store the individual DataFrames\n",
    "chunk_dfs = []\n",
    "\n",
    "# Create an iterator to read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk and store them in the list\n",
    "for chunk in chunk_iterator:\n",
    "    #  appending each chunk to the list\n",
    "    chunk_dfs.append(chunk)\n",
    "\n",
    "# Concatenate all the chunks into a single DataFrame\n",
    "sparse_df_boolean = pd.concat(chunk_dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "sparse_df_boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02301244",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents consequents  antecedent support  consequent support   support  \\\n",
      "0        (720)      (3258)            0.078597            0.017753  0.011172   \n",
      "1       (3258)       (720)            0.017753            0.078597  0.011172   \n",
      "2        (365)       (319)            0.086645            0.082352  0.016870   \n",
      "3        (319)       (365)            0.082352            0.086645  0.016870   \n",
      "4        (720)       (365)            0.078597            0.086645  0.010260   \n",
      "5        (365)       (720)            0.086645            0.078597  0.010260   \n",
      "6        (365)       (294)            0.086645            0.050817  0.018033   \n",
      "7        (294)       (365)            0.050817            0.086645  0.018033   \n",
      "8        (387)       (294)            0.059008            0.050817  0.011487   \n",
      "9        (294)       (387)            0.050817            0.059008  0.011487   \n",
      "10      (1000)      (1003)            0.050499            0.040979  0.011990   \n",
      "11      (1003)      (1000)            0.040979            0.050499  0.011990   \n",
      "12       (292)       (365)            0.037166            0.086645  0.011119   \n",
      "13       (365)       (292)            0.086645            0.037166  0.011119   \n",
      "14       (292)       (294)            0.037166            0.050817  0.010727   \n",
      "15       (294)       (292)            0.050817            0.037166  0.010727   \n",
      "16       (720)      (3276)            0.078597            0.040796  0.020422   \n",
      "17      (3276)       (720)            0.040796            0.078597  0.020422   \n",
      "18       (720)      (2603)            0.078597            0.054308  0.016208   \n",
      "19      (2603)       (720)            0.054308            0.078597  0.016208   \n",
      "20       (387)       (365)            0.059008            0.086645  0.030362   \n",
      "21       (365)       (387)            0.086645            0.059008  0.030362   \n",
      "22       (387)       (319)            0.059008            0.082352  0.012288   \n",
      "23       (319)       (387)            0.082352            0.059008  0.012288   \n",
      "\n",
      "    confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0     0.142144  8.006698  0.009777    1.145002       0.949752  \n",
      "1     0.629299  8.006698  0.009777    2.485572       0.890921  \n",
      "2     0.194700  2.364239  0.009734    1.139510       0.631771  \n",
      "3     0.204850  2.364239  0.009734    1.148657       0.628815  \n",
      "4     0.130540  1.506600  0.003450    1.050485       0.364937  \n",
      "5     0.118414  1.506600  0.003450    1.045165       0.368153  \n",
      "6     0.208127  4.095599  0.013630    1.198655       0.827538  \n",
      "7     0.354864  4.095599  0.013630    1.415755       0.796301  \n",
      "8     0.194669  3.830770  0.008488    1.178624       0.785294  \n",
      "9     0.226045  3.830770  0.008488    1.215823       0.778518  \n",
      "10    0.237436  5.794148  0.009921    1.257627       0.871417  \n",
      "11    0.292597  5.794148  0.009921    1.342235       0.862767  \n",
      "12    0.299172  3.452845  0.007899    1.303251       0.737805  \n",
      "13    0.128327  3.452845  0.007899    1.104582       0.777774  \n",
      "14    0.288619  5.679550  0.008838    1.334281       0.855734  \n",
      "15    0.211084  5.679550  0.008838    1.220452       0.868041  \n",
      "16    0.259831  6.369026  0.017215    1.295926       0.914898  \n",
      "17    0.500584  6.369026  0.017215    1.844961       0.878843  \n",
      "18    0.206212  3.797116  0.011939    1.191367       0.799478  \n",
      "19    0.298440  3.797116  0.011939    1.313364       0.778945  \n",
      "20    0.514544  5.938527  0.025249    1.881439       0.883756  \n",
      "21    0.350419  5.938527  0.025249    1.448613       0.910498  \n",
      "22    0.208242  2.528687  0.007429    1.159001       0.642447  \n",
      "23    0.149212  2.528687  0.007429    1.106024       0.658791  \n",
      "      support     itemsets\n",
      "0    0.086645        (365)\n",
      "1    0.072977       (2717)\n",
      "2    0.055892        (444)\n",
      "3    0.046473        (577)\n",
      "4    0.036788       (3814)\n",
      "..        ...          ...\n",
      "203  0.010727   (292, 294)\n",
      "204  0.020422  (720, 3276)\n",
      "205  0.016208  (720, 2603)\n",
      "206  0.030362   (387, 365)\n",
      "207  0.012288   (387, 319)\n",
      "\n",
      "[208 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'sparse_df' is the DataFrame obtained from the sparse matrix\n",
    "# Perform association rule mining on the DataFrame\n",
    "# = apriori(sparse_df, min_support=0.0009, use_colnames=True)\n",
    "#rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.1)\n",
    "\n",
    "frequent_itemsets = fpgrowth(sparse_df_boolean, min_support=0.01, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.01)\n",
    "\n",
    "# Explore and interpret the generated association rules\n",
    "print(rules)\n",
    "print(frequent_itemsets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98844b77-d854-45bc-b2f6-3ee4e1768a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the column names for the DataFrame\n",
    "columns = ['support', 'itemsets']\n",
    "\n",
    "# Convert association_rules to a DataFrame\n",
    "frequent_itemsets_df = pd.DataFrame(frequent_itemsets, columns=columns)\n",
    "\n",
    "# Specify the file path to save the CSV file\n",
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MyMarket2/frequent_itemsets.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "frequent_itemsets_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac500568-b5a7-46e2-b394-ee24e1a69186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents consequents  antecedent support  consequent support   support  \\\n",
      "0        (720)      (3258)            0.078597            0.017753  0.011172   \n",
      "1       (3258)       (720)            0.017753            0.078597  0.011172   \n",
      "2        (365)       (319)            0.086645            0.082352  0.016870   \n",
      "3        (319)       (365)            0.082352            0.086645  0.016870   \n",
      "4        (720)       (365)            0.078597            0.086645  0.010260   \n",
      "5        (365)       (720)            0.086645            0.078597  0.010260   \n",
      "6        (365)       (294)            0.086645            0.050817  0.018033   \n",
      "7        (294)       (365)            0.050817            0.086645  0.018033   \n",
      "8        (387)       (294)            0.059008            0.050817  0.011487   \n",
      "9        (294)       (387)            0.050817            0.059008  0.011487   \n",
      "10      (1000)      (1003)            0.050499            0.040979  0.011990   \n",
      "11      (1003)      (1000)            0.040979            0.050499  0.011990   \n",
      "12       (292)       (365)            0.037166            0.086645  0.011119   \n",
      "13       (365)       (292)            0.086645            0.037166  0.011119   \n",
      "14       (292)       (294)            0.037166            0.050817  0.010727   \n",
      "15       (294)       (292)            0.050817            0.037166  0.010727   \n",
      "16       (720)      (3276)            0.078597            0.040796  0.020422   \n",
      "17      (3276)       (720)            0.040796            0.078597  0.020422   \n",
      "18       (720)      (2603)            0.078597            0.054308  0.016208   \n",
      "19      (2603)       (720)            0.054308            0.078597  0.016208   \n",
      "20       (387)       (365)            0.059008            0.086645  0.030362   \n",
      "21       (365)       (387)            0.086645            0.059008  0.030362   \n",
      "22       (387)       (319)            0.059008            0.082352  0.012288   \n",
      "23       (319)       (387)            0.082352            0.059008  0.012288   \n",
      "\n",
      "    confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0     0.142144  8.006698  0.009777    1.145002       0.949752  \n",
      "1     0.629299  8.006698  0.009777    2.485572       0.890921  \n",
      "2     0.194700  2.364239  0.009734    1.139510       0.631771  \n",
      "3     0.204850  2.364239  0.009734    1.148657       0.628815  \n",
      "4     0.130540  1.506600  0.003450    1.050485       0.364937  \n",
      "5     0.118414  1.506600  0.003450    1.045165       0.368153  \n",
      "6     0.208127  4.095599  0.013630    1.198655       0.827538  \n",
      "7     0.354864  4.095599  0.013630    1.415755       0.796301  \n",
      "8     0.194669  3.830770  0.008488    1.178624       0.785294  \n",
      "9     0.226045  3.830770  0.008488    1.215823       0.778518  \n",
      "10    0.237436  5.794148  0.009921    1.257627       0.871417  \n",
      "11    0.292597  5.794148  0.009921    1.342235       0.862767  \n",
      "12    0.299172  3.452845  0.007899    1.303251       0.737805  \n",
      "13    0.128327  3.452845  0.007899    1.104582       0.777774  \n",
      "14    0.288619  5.679550  0.008838    1.334281       0.855734  \n",
      "15    0.211084  5.679550  0.008838    1.220452       0.868041  \n",
      "16    0.259831  6.369026  0.017215    1.295926       0.914898  \n",
      "17    0.500584  6.369026  0.017215    1.844961       0.878843  \n",
      "18    0.206212  3.797116  0.011939    1.191367       0.799478  \n",
      "19    0.298440  3.797116  0.011939    1.313364       0.778945  \n",
      "20    0.514544  5.938527  0.025249    1.881439       0.883756  \n",
      "21    0.350419  5.938527  0.025249    1.448613       0.910498  \n",
      "22    0.208242  2.528687  0.007429    1.159001       0.642447  \n",
      "23    0.149212  2.528687  0.007429    1.106024       0.658791  \n"
     ]
    }
   ],
   "source": [
    "# Define the column names for the DataFrame\n",
    "columns1 = ['Antecedents', 'Consequents', 'Antecedents Support', 'Consequents Support',\n",
    "           'Support', 'Confidence', 'Lift', 'Leverage', 'Conviction', \"Zhang's Metric\"]\n",
    "\n",
    "# Convert association_rules to a DataFrame\n",
    "rules_df = pd.DataFrame(rules)\n",
    "print(rules_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72d091-5524-42b9-8811-fae43b38b2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94bfd43-a741-4394-8820-f3769c4d8afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defrost 'frozenset' to regular sets and access their elements\n",
    "rules_df['consequents'] = rules_df['consequents'].apply(lambda x: set(x))\n",
    "\n",
    "# Accessing defrosted elements\n",
    "for index, row in rules_df.iterrows():\n",
    "    print(f\"Row {index + 1}: {row['consequents']}\")\n",
    "    # Access elements of the set\n",
    "    for element in row['consequents']:\n",
    "        print(f\"Element: {element}\")\n",
    "\n",
    "print(rules_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e704f1-3bd5-42e2-aab6-193da207bdac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have 'rules_df' and 'filtered_df' DataFrames\n",
    "\n",
    "# Example merge based on columns 'antecedents' and 'ID'\n",
    "merged_df = pd.merge(rules_df, filtered_df[['ID', 'COMBINED']], left_on='antecedents', right_on='ID', how='left')\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e43b6e26-bef0-47d8-8374-2dfa724a4a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents retrieved_antecedents_combined\n",
      "0        (720)                      [1_1_4_3]\n",
      "1       (3258)                      [6_1_1_1]\n",
      "2        (365)                    [15_3_13_1]\n",
      "3        (319)                    [15_1_24_1]\n",
      "4        (720)                      [1_1_4_3]\n",
      "5        (365)                    [15_3_13_1]\n",
      "6        (365)                    [15_3_13_1]\n",
      "7        (294)                    [15_12_2_1]\n",
      "8        (387)                    [15_3_18_1]\n",
      "9        (294)                    [15_12_2_1]\n",
      "10      (1000)                    [23_30_1_2]\n",
      "11      (1003)                    [23_30_2_2]\n",
      "12       (292)                    [15_12_1_1]\n",
      "13       (365)                    [15_3_13_1]\n",
      "14       (292)                    [15_12_1_1]\n",
      "15       (294)                    [15_12_2_1]\n",
      "16       (720)                      [1_1_4_3]\n",
      "17      (3276)                      [6_1_3_2]\n",
      "18       (720)                      [1_1_4_3]\n",
      "19      (2603)                    [49_1_1_11]\n",
      "20       (387)                    [15_3_18_1]\n",
      "21       (365)                    [15_3_13_1]\n",
      "22       (387)                    [15_3_18_1]\n",
      "23       (319)                    [15_1_24_1]\n"
     ]
    }
   ],
   "source": [
    "def retrieve_combined(row):\n",
    "    return [product_ids[col_index] for col_index in row['antecedents']]\n",
    "\n",
    "rules_df['retrieved_antecedents_combined'] = rules_df.apply(retrieve_combined, axis=1)\n",
    "\n",
    "print(rules_df[['antecedents', 'retrieved_antecedents_combined']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e475f19-0f7b-4882-be1d-95cfb4cf89a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>retrieved_consequents_combined</th>\n",
       "      <th>retrieved_antecedents_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(720)</td>\n",
       "      <td>(3258)</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.142144</td>\n",
       "      <td>8.006698</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>1.145002</td>\n",
       "      <td>0.949752</td>\n",
       "      <td>[6_1_1_1]</td>\n",
       "      <td>[1_1_4_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3258)</td>\n",
       "      <td>(720)</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.629299</td>\n",
       "      <td>8.006698</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>2.485572</td>\n",
       "      <td>0.890921</td>\n",
       "      <td>[1_1_4_3]</td>\n",
       "      <td>[6_1_1_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(365)</td>\n",
       "      <td>(319)</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.082352</td>\n",
       "      <td>0.016870</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>2.364239</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>1.139510</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>[15_1_24_1]</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(319)</td>\n",
       "      <td>(365)</td>\n",
       "      <td>0.082352</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.016870</td>\n",
       "      <td>0.204850</td>\n",
       "      <td>2.364239</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>1.148657</td>\n",
       "      <td>0.628815</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "      <td>[15_1_24_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(720)</td>\n",
       "      <td>(365)</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>1.506600</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>1.050485</td>\n",
       "      <td>0.364937</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "      <td>[1_1_4_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(365)</td>\n",
       "      <td>(720)</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>0.118414</td>\n",
       "      <td>1.506600</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>1.045165</td>\n",
       "      <td>0.368153</td>\n",
       "      <td>[1_1_4_3]</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(365)</td>\n",
       "      <td>(294)</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.050817</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.208127</td>\n",
       "      <td>4.095599</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>1.198655</td>\n",
       "      <td>0.827538</td>\n",
       "      <td>[15_12_2_1]</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(294)</td>\n",
       "      <td>(365)</td>\n",
       "      <td>0.050817</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.354864</td>\n",
       "      <td>4.095599</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>1.415755</td>\n",
       "      <td>0.796301</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "      <td>[15_12_2_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(387)</td>\n",
       "      <td>(294)</td>\n",
       "      <td>0.059008</td>\n",
       "      <td>0.050817</td>\n",
       "      <td>0.011487</td>\n",
       "      <td>0.194669</td>\n",
       "      <td>3.830770</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>1.178624</td>\n",
       "      <td>0.785294</td>\n",
       "      <td>[15_12_2_1]</td>\n",
       "      <td>[15_3_18_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(294)</td>\n",
       "      <td>(387)</td>\n",
       "      <td>0.050817</td>\n",
       "      <td>0.059008</td>\n",
       "      <td>0.011487</td>\n",
       "      <td>0.226045</td>\n",
       "      <td>3.830770</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>1.215823</td>\n",
       "      <td>0.778518</td>\n",
       "      <td>[15_3_18_1]</td>\n",
       "      <td>[15_12_2_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1000)</td>\n",
       "      <td>(1003)</td>\n",
       "      <td>0.050499</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.237436</td>\n",
       "      <td>5.794148</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>1.257627</td>\n",
       "      <td>0.871417</td>\n",
       "      <td>[23_30_2_2]</td>\n",
       "      <td>[23_30_1_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1003)</td>\n",
       "      <td>(1000)</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.050499</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.292597</td>\n",
       "      <td>5.794148</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>1.342235</td>\n",
       "      <td>0.862767</td>\n",
       "      <td>[23_30_1_2]</td>\n",
       "      <td>[23_30_2_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(292)</td>\n",
       "      <td>(365)</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.011119</td>\n",
       "      <td>0.299172</td>\n",
       "      <td>3.452845</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>1.303251</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "      <td>[15_12_1_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(365)</td>\n",
       "      <td>(292)</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.011119</td>\n",
       "      <td>0.128327</td>\n",
       "      <td>3.452845</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>1.104582</td>\n",
       "      <td>0.777774</td>\n",
       "      <td>[15_12_1_1]</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(292)</td>\n",
       "      <td>(294)</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.050817</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.288619</td>\n",
       "      <td>5.679550</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>1.334281</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>[15_12_2_1]</td>\n",
       "      <td>[15_12_1_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(294)</td>\n",
       "      <td>(292)</td>\n",
       "      <td>0.050817</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.211084</td>\n",
       "      <td>5.679550</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>1.220452</td>\n",
       "      <td>0.868041</td>\n",
       "      <td>[15_12_1_1]</td>\n",
       "      <td>[15_12_2_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(720)</td>\n",
       "      <td>(3276)</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>0.259831</td>\n",
       "      <td>6.369026</td>\n",
       "      <td>0.017215</td>\n",
       "      <td>1.295926</td>\n",
       "      <td>0.914898</td>\n",
       "      <td>[6_1_3_2]</td>\n",
       "      <td>[1_1_4_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(3276)</td>\n",
       "      <td>(720)</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>0.500584</td>\n",
       "      <td>6.369026</td>\n",
       "      <td>0.017215</td>\n",
       "      <td>1.844961</td>\n",
       "      <td>0.878843</td>\n",
       "      <td>[1_1_4_3]</td>\n",
       "      <td>[6_1_3_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(720)</td>\n",
       "      <td>(2603)</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.054308</td>\n",
       "      <td>0.016208</td>\n",
       "      <td>0.206212</td>\n",
       "      <td>3.797116</td>\n",
       "      <td>0.011939</td>\n",
       "      <td>1.191367</td>\n",
       "      <td>0.799478</td>\n",
       "      <td>[49_1_1_11]</td>\n",
       "      <td>[1_1_4_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(2603)</td>\n",
       "      <td>(720)</td>\n",
       "      <td>0.054308</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.016208</td>\n",
       "      <td>0.298440</td>\n",
       "      <td>3.797116</td>\n",
       "      <td>0.011939</td>\n",
       "      <td>1.313364</td>\n",
       "      <td>0.778945</td>\n",
       "      <td>[1_1_4_3]</td>\n",
       "      <td>[49_1_1_11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(387)</td>\n",
       "      <td>(365)</td>\n",
       "      <td>0.059008</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>0.514544</td>\n",
       "      <td>5.938527</td>\n",
       "      <td>0.025249</td>\n",
       "      <td>1.881439</td>\n",
       "      <td>0.883756</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "      <td>[15_3_18_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(365)</td>\n",
       "      <td>(387)</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.059008</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>0.350419</td>\n",
       "      <td>5.938527</td>\n",
       "      <td>0.025249</td>\n",
       "      <td>1.448613</td>\n",
       "      <td>0.910498</td>\n",
       "      <td>[15_3_18_1]</td>\n",
       "      <td>[15_3_13_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(387)</td>\n",
       "      <td>(319)</td>\n",
       "      <td>0.059008</td>\n",
       "      <td>0.082352</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.208242</td>\n",
       "      <td>2.528687</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>1.159001</td>\n",
       "      <td>0.642447</td>\n",
       "      <td>[15_1_24_1]</td>\n",
       "      <td>[15_3_18_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(319)</td>\n",
       "      <td>(387)</td>\n",
       "      <td>0.082352</td>\n",
       "      <td>0.059008</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.149212</td>\n",
       "      <td>2.528687</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>1.106024</td>\n",
       "      <td>0.658791</td>\n",
       "      <td>[15_3_18_1]</td>\n",
       "      <td>[15_1_24_1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0        (720)      (3258)            0.078597            0.017753  0.011172   \n",
       "1       (3258)       (720)            0.017753            0.078597  0.011172   \n",
       "2        (365)       (319)            0.086645            0.082352  0.016870   \n",
       "3        (319)       (365)            0.082352            0.086645  0.016870   \n",
       "4        (720)       (365)            0.078597            0.086645  0.010260   \n",
       "5        (365)       (720)            0.086645            0.078597  0.010260   \n",
       "6        (365)       (294)            0.086645            0.050817  0.018033   \n",
       "7        (294)       (365)            0.050817            0.086645  0.018033   \n",
       "8        (387)       (294)            0.059008            0.050817  0.011487   \n",
       "9        (294)       (387)            0.050817            0.059008  0.011487   \n",
       "10      (1000)      (1003)            0.050499            0.040979  0.011990   \n",
       "11      (1003)      (1000)            0.040979            0.050499  0.011990   \n",
       "12       (292)       (365)            0.037166            0.086645  0.011119   \n",
       "13       (365)       (292)            0.086645            0.037166  0.011119   \n",
       "14       (292)       (294)            0.037166            0.050817  0.010727   \n",
       "15       (294)       (292)            0.050817            0.037166  0.010727   \n",
       "16       (720)      (3276)            0.078597            0.040796  0.020422   \n",
       "17      (3276)       (720)            0.040796            0.078597  0.020422   \n",
       "18       (720)      (2603)            0.078597            0.054308  0.016208   \n",
       "19      (2603)       (720)            0.054308            0.078597  0.016208   \n",
       "20       (387)       (365)            0.059008            0.086645  0.030362   \n",
       "21       (365)       (387)            0.086645            0.059008  0.030362   \n",
       "22       (387)       (319)            0.059008            0.082352  0.012288   \n",
       "23       (319)       (387)            0.082352            0.059008  0.012288   \n",
       "\n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \\\n",
       "0     0.142144  8.006698  0.009777    1.145002       0.949752   \n",
       "1     0.629299  8.006698  0.009777    2.485572       0.890921   \n",
       "2     0.194700  2.364239  0.009734    1.139510       0.631771   \n",
       "3     0.204850  2.364239  0.009734    1.148657       0.628815   \n",
       "4     0.130540  1.506600  0.003450    1.050485       0.364937   \n",
       "5     0.118414  1.506600  0.003450    1.045165       0.368153   \n",
       "6     0.208127  4.095599  0.013630    1.198655       0.827538   \n",
       "7     0.354864  4.095599  0.013630    1.415755       0.796301   \n",
       "8     0.194669  3.830770  0.008488    1.178624       0.785294   \n",
       "9     0.226045  3.830770  0.008488    1.215823       0.778518   \n",
       "10    0.237436  5.794148  0.009921    1.257627       0.871417   \n",
       "11    0.292597  5.794148  0.009921    1.342235       0.862767   \n",
       "12    0.299172  3.452845  0.007899    1.303251       0.737805   \n",
       "13    0.128327  3.452845  0.007899    1.104582       0.777774   \n",
       "14    0.288619  5.679550  0.008838    1.334281       0.855734   \n",
       "15    0.211084  5.679550  0.008838    1.220452       0.868041   \n",
       "16    0.259831  6.369026  0.017215    1.295926       0.914898   \n",
       "17    0.500584  6.369026  0.017215    1.844961       0.878843   \n",
       "18    0.206212  3.797116  0.011939    1.191367       0.799478   \n",
       "19    0.298440  3.797116  0.011939    1.313364       0.778945   \n",
       "20    0.514544  5.938527  0.025249    1.881439       0.883756   \n",
       "21    0.350419  5.938527  0.025249    1.448613       0.910498   \n",
       "22    0.208242  2.528687  0.007429    1.159001       0.642447   \n",
       "23    0.149212  2.528687  0.007429    1.106024       0.658791   \n",
       "\n",
       "   retrieved_consequents_combined retrieved_antecedents_combined  \n",
       "0                       [6_1_1_1]                      [1_1_4_3]  \n",
       "1                       [1_1_4_3]                      [6_1_1_1]  \n",
       "2                     [15_1_24_1]                    [15_3_13_1]  \n",
       "3                     [15_3_13_1]                    [15_1_24_1]  \n",
       "4                     [15_3_13_1]                      [1_1_4_3]  \n",
       "5                       [1_1_4_3]                    [15_3_13_1]  \n",
       "6                     [15_12_2_1]                    [15_3_13_1]  \n",
       "7                     [15_3_13_1]                    [15_12_2_1]  \n",
       "8                     [15_12_2_1]                    [15_3_18_1]  \n",
       "9                     [15_3_18_1]                    [15_12_2_1]  \n",
       "10                    [23_30_2_2]                    [23_30_1_2]  \n",
       "11                    [23_30_1_2]                    [23_30_2_2]  \n",
       "12                    [15_3_13_1]                    [15_12_1_1]  \n",
       "13                    [15_12_1_1]                    [15_3_13_1]  \n",
       "14                    [15_12_2_1]                    [15_12_1_1]  \n",
       "15                    [15_12_1_1]                    [15_12_2_1]  \n",
       "16                      [6_1_3_2]                      [1_1_4_3]  \n",
       "17                      [1_1_4_3]                      [6_1_3_2]  \n",
       "18                    [49_1_1_11]                      [1_1_4_3]  \n",
       "19                      [1_1_4_3]                    [49_1_1_11]  \n",
       "20                    [15_3_13_1]                    [15_3_18_1]  \n",
       "21                    [15_3_18_1]                    [15_3_13_1]  \n",
       "22                    [15_1_24_1]                    [15_3_18_1]  \n",
       "23                    [15_3_18_1]                    [15_1_24_1]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03073d83-0ec7-405a-9b5e-fe3e602d37dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        itemsets      retrieved_itemsets\n",
      "0          (365)             [15_3_13_1]\n",
      "1         (2717)            [51_11_10_3]\n",
      "2          (444)              [15_6_1_2]\n",
      "3          (577)              [17_1_2_2]\n",
      "4         (3814)            [81_31_14_1]\n",
      "..           ...                     ...\n",
      "203   (292, 294)  [15_12_1_1, 15_12_2_1]\n",
      "204  (720, 3276)      [1_1_4_3, 6_1_3_2]\n",
      "205  (720, 2603)    [1_1_4_3, 49_1_1_11]\n",
      "206   (387, 365)  [15_3_18_1, 15_3_13_1]\n",
      "207   (387, 319)  [15_3_18_1, 15_1_24_1]\n",
      "\n",
      "[208 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def retrieve_combined(row):\n",
    "    return [product_ids[col_index] for col_index in row['itemsets']]\n",
    "\n",
    "frequent_itemsets_df['retrieved_itemsets'] = frequent_itemsets_df.apply(retrieve_combined, axis=1)\n",
    "\n",
    "print(frequent_itemsets_df[['itemsets', 'retrieved_itemsets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02197f3d-dc17-4502-a937-343381eafcfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the file path to save the CSV file\n",
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MYMARKET/rules.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "rules_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132f2da-5035-4d53-a0d7-602e2bb66315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the file path to save the CSV file\n",
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MYMARKET/frequent_itemsets.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "frequent_itemsets_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e6d5c72-fccf-4734-8b4b-cbed640b3c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ITH_SECTION_CODE                 ITH_SECTION_DESC  ITH_DEPT_CODE  \\\n",
      "0                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "1                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "2                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "3                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "4                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "...                 ...                              ...            ...   \n",
      "39079                31              ΚΑΦΕΔΕΣ - ΑΦΕΨΗΜΑΤΑ             21   \n",
      "39080                31              ΚΑΦΕΔΕΣ - ΑΦΕΨΗΜΑΤΑ             21   \n",
      "39081                49                   ΑΡΤΟΣΚΕΥΑΣΜΑΤΑ              1   \n",
      "39082                48                            ΓΛΥΚΑ             57   \n",
      "39083                48                            ΓΛΥΚΑ             51   \n",
      "\n",
      "                 ITH_DEPT_DESC  ITH_CATEG_CODE         ITH_CATEG_DESC  \\\n",
      "0           ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "1           ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "2           ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "3           ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "4           ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "...                        ...             ...                    ...   \n",
      "39079          ΚAΦΕΔΕΣ ΦΙΛΤΡΟΥ               4                DIMELLO   \n",
      "39080          ΚAΦΕΔΕΣ ΦΙΛΤΡΟΥ               4                DIMELLO   \n",
      "39081             ΨΩΜΙ ΣΥΣΚ/ΝΟ               1                   ΤΟΣΤ   \n",
      "39082                 ΕΠΟΧΙΑΚΑ               1               ΕΠΟΧΙΑΚΑ   \n",
      "39083  ΠΡΟΙΟΝΤΑ ΣΟΚΟΛΑΤΟΠΟΙΙΑΣ              11            ΣΟΚΟΛΑΤΑΚΙΑ   \n",
      "\n",
      "      ITH_GROUP_CODE       ITH_GROUP_DESC  \n",
      "0                 01   ΣΤΑΦΙΔΑ ΣΟΥΛΤΑΝΙΝΑ  \n",
      "1                 01   ΣΤΑΦΙΔΑ ΣΟΥΛΤΑΝΙΝΑ  \n",
      "2                 02        ΣΤΑΦΙΔΑ ΜΑΥΡΗ  \n",
      "3                 02        ΣΤΑΦΙΔΑ ΜΑΥΡΗ  \n",
      "4                 04       ΣΤΑΦΥΛΙ GOLDEN  \n",
      "...              ...                  ...  \n",
      "39079             05            ΦΟΥΝΤΟΥΚΙ  \n",
      "39080             06             ΚΑΡΑΜΕΛΑ  \n",
      "39081             41  ΦΟΡΜΑ ΕΠΑΓΓΕΛΜΑΤΙΚΗ  \n",
      "39082             01             ΕΠΟΧΙΑΚΑ  \n",
      "39083             11                KOYTI  \n",
      "\n",
      "[39084 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example: Load specific columns ('col1', 'col2', 'col3') from a CSV file into a DataFrame\n",
    "file_path = 'C:/Users/Lazaros.Sofikitis/Desktop/MYMARKET/ITEMTREEHIER_DIM.csv'\n",
    "\n",
    "# Specify the columns you want to load\n",
    "columns_to_load = [ 'ITH_SECTION_CODE', 'ITH_SECTION_DESC', 'ITH_DEPT_CODE', 'ITH_DEPT_DESC',\n",
    "                   'ITH_CATEG_CODE', 'ITH_CATEG_DESC', 'ITH_GROUP_CODE', 'ITH_GROUP_DESC']\n",
    "\n",
    "# Load the specific columns into a DataFrame\n",
    "df_item_tree = pd.read_csv(file_path, usecols=columns_to_load)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(df_item_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "376fc5d5-b70e-4513-8cd6-bbc456966bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ITH_SECTION_CODE                 ITH_SECTION_DESC  ITH_DEPT_CODE  \\\n",
      "0                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "2                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "4                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "5                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "6                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
      "...                 ...                              ...            ...   \n",
      "39065                35                           ΠΡΩΙΝΟ              1   \n",
      "39071                22              ΣΥΝΟΔΕΥΤΙΚΑ ΦΑΓΗΤΩΝ             21   \n",
      "39078                22              ΣΥΝΟΔΕΥΤΙΚΑ ΦΑΓΗΤΩΝ             20   \n",
      "39079                31              ΚΑΦΕΔΕΣ - ΑΦΕΨΗΜΑΤΑ             21   \n",
      "39080                31              ΚΑΦΕΔΕΣ - ΑΦΕΨΗΜΑΤΑ             21   \n",
      "\n",
      "            ITH_DEPT_DESC  ITH_CATEG_CODE         ITH_CATEG_DESC  \\\n",
      "0      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "2      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "4      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "5      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "6      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
      "...                   ...             ...                    ...   \n",
      "39065          ΔΗΜΗΤΡΙΑΚΑ               5           NUTRI VALLEY   \n",
      "39071   ΣΑΛΤΣΕΣ ΖΥΜΑΡIKΩΝ              11           ΓΥΑΛΙΝΟ ΒΑΖΟ   \n",
      "39078   ΣΑΛΤΣΕΣ ΓΙΑ ΚΡΕΑΣ              21               CATERING   \n",
      "39079     ΚAΦΕΔΕΣ ΦΙΛΤΡΟΥ               4                DIMELLO   \n",
      "39080     ΚAΦΕΔΕΣ ΦΙΛΤΡΟΥ               4                DIMELLO   \n",
      "\n",
      "      ITH_GROUP_CODE      ITH_GROUP_DESC  \n",
      "0                 01  ΣΤΑΦΙΔΑ ΣΟΥΛΤΑΝΙΝΑ  \n",
      "2                 02       ΣΤΑΦΙΔΑ ΜΑΥΡΗ  \n",
      "4                 04      ΣΤΑΦΥΛΙ GOLDEN  \n",
      "5                 05   ΔΑΜΑΣΚΗΝΑ ΑΠΥΡΗΝΑ  \n",
      "6                 07            ΒΕΡΥΚΟΚΑ  \n",
      "...              ...                 ...  \n",
      "39065             01             GRANOLA  \n",
      "39071             13               ZANAE  \n",
      "39078             07             CONDITO  \n",
      "39079             05           ΦΟΥΝΤΟΥΚΙ  \n",
      "39080             06            ΚΑΡΑΜΕΛΑ  \n",
      "\n",
      "[10195 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove duplicate rows\n",
    "df_item_tree.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(df_item_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18b487ae-2748-45f2-858d-65db9f2c90a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITH_SECTION_CODE</th>\n",
       "      <th>ITH_SECTION_DESC</th>\n",
       "      <th>ITH_DEPT_CODE</th>\n",
       "      <th>ITH_DEPT_DESC</th>\n",
       "      <th>ITH_CATEG_CODE</th>\n",
       "      <th>ITH_CATEG_DESC</th>\n",
       "      <th>ITH_GROUP_CODE</th>\n",
       "      <th>ITH_GROUP_DESC</th>\n",
       "      <th>COMBINED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>2</td>\n",
       "      <td>ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>1</td>\n",
       "      <td>ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G</td>\n",
       "      <td>1</td>\n",
       "      <td>ΣΤΑΦΙΔΑ ΣΟΥΛΤΑΝΙΝΑ</td>\n",
       "      <td>8_2_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>2</td>\n",
       "      <td>ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>1</td>\n",
       "      <td>ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G</td>\n",
       "      <td>2</td>\n",
       "      <td>ΣΤΑΦΙΔΑ ΜΑΥΡΗ</td>\n",
       "      <td>8_2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>2</td>\n",
       "      <td>ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>1</td>\n",
       "      <td>ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G</td>\n",
       "      <td>4</td>\n",
       "      <td>ΣΤΑΦΥΛΙ GOLDEN</td>\n",
       "      <td>8_2_1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>2</td>\n",
       "      <td>ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>1</td>\n",
       "      <td>ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G</td>\n",
       "      <td>5</td>\n",
       "      <td>ΔΑΜΑΣΚΗΝΑ ΑΠΥΡΗΝΑ</td>\n",
       "      <td>8_2_1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>2</td>\n",
       "      <td>ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ</td>\n",
       "      <td>1</td>\n",
       "      <td>ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G</td>\n",
       "      <td>7</td>\n",
       "      <td>ΒΕΡΥΚΟΚΑ</td>\n",
       "      <td>8_2_1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39065</th>\n",
       "      <td>35</td>\n",
       "      <td>ΠΡΩΙΝΟ</td>\n",
       "      <td>1</td>\n",
       "      <td>ΔΗΜΗΤΡΙΑΚΑ</td>\n",
       "      <td>5</td>\n",
       "      <td>NUTRI VALLEY</td>\n",
       "      <td>1</td>\n",
       "      <td>GRANOLA</td>\n",
       "      <td>35_1_5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39071</th>\n",
       "      <td>22</td>\n",
       "      <td>ΣΥΝΟΔΕΥΤΙΚΑ ΦΑΓΗΤΩΝ</td>\n",
       "      <td>21</td>\n",
       "      <td>ΣΑΛΤΣΕΣ ΖΥΜΑΡIKΩΝ</td>\n",
       "      <td>11</td>\n",
       "      <td>ΓΥΑΛΙΝΟ ΒΑΖΟ</td>\n",
       "      <td>13</td>\n",
       "      <td>ZANAE</td>\n",
       "      <td>22_21_11_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39078</th>\n",
       "      <td>22</td>\n",
       "      <td>ΣΥΝΟΔΕΥΤΙΚΑ ΦΑΓΗΤΩΝ</td>\n",
       "      <td>20</td>\n",
       "      <td>ΣΑΛΤΣΕΣ ΓΙΑ ΚΡΕΑΣ</td>\n",
       "      <td>21</td>\n",
       "      <td>CATERING</td>\n",
       "      <td>7</td>\n",
       "      <td>CONDITO</td>\n",
       "      <td>22_20_21_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39079</th>\n",
       "      <td>31</td>\n",
       "      <td>ΚΑΦΕΔΕΣ - ΑΦΕΨΗΜΑΤΑ</td>\n",
       "      <td>21</td>\n",
       "      <td>ΚAΦΕΔΕΣ ΦΙΛΤΡΟΥ</td>\n",
       "      <td>4</td>\n",
       "      <td>DIMELLO</td>\n",
       "      <td>5</td>\n",
       "      <td>ΦΟΥΝΤΟΥΚΙ</td>\n",
       "      <td>31_21_4_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39080</th>\n",
       "      <td>31</td>\n",
       "      <td>ΚΑΦΕΔΕΣ - ΑΦΕΨΗΜΑΤΑ</td>\n",
       "      <td>21</td>\n",
       "      <td>ΚAΦΕΔΕΣ ΦΙΛΤΡΟΥ</td>\n",
       "      <td>4</td>\n",
       "      <td>DIMELLO</td>\n",
       "      <td>6</td>\n",
       "      <td>ΚΑΡΑΜΕΛΑ</td>\n",
       "      <td>31_21_4_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10195 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ITH_SECTION_CODE                 ITH_SECTION_DESC  ITH_DEPT_CODE  \\\n",
       "0                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
       "2                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
       "4                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
       "5                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
       "6                     8  ΞΗΡΟΙ ΚΑΡΠΟΙ-ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ              2   \n",
       "...                 ...                              ...            ...   \n",
       "39065                35                           ΠΡΩΙΝΟ              1   \n",
       "39071                22              ΣΥΝΟΔΕΥΤΙΚΑ ΦΑΓΗΤΩΝ             21   \n",
       "39078                22              ΣΥΝΟΔΕΥΤΙΚΑ ΦΑΓΗΤΩΝ             20   \n",
       "39079                31              ΚΑΦΕΔΕΣ - ΑΦΕΨΗΜΑΤΑ             21   \n",
       "39080                31              ΚΑΦΕΔΕΣ - ΑΦΕΨΗΜΑΤΑ             21   \n",
       "\n",
       "            ITH_DEPT_DESC  ITH_CATEG_CODE         ITH_CATEG_DESC  \\\n",
       "0      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
       "2      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
       "4      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
       "5      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
       "6      ΑΠΟΞΗΡΑΜΕΝΑ ΦΡΟΥΤΑ               1  ΣΥΣΚΕΥΑΣΜΕΝΑ 150-200G   \n",
       "...                   ...             ...                    ...   \n",
       "39065          ΔΗΜΗΤΡΙΑΚΑ               5           NUTRI VALLEY   \n",
       "39071   ΣΑΛΤΣΕΣ ΖΥΜΑΡIKΩΝ              11           ΓΥΑΛΙΝΟ ΒΑΖΟ   \n",
       "39078   ΣΑΛΤΣΕΣ ΓΙΑ ΚΡΕΑΣ              21               CATERING   \n",
       "39079     ΚAΦΕΔΕΣ ΦΙΛΤΡΟΥ               4                DIMELLO   \n",
       "39080     ΚAΦΕΔΕΣ ΦΙΛΤΡΟΥ               4                DIMELLO   \n",
       "\n",
       "      ITH_GROUP_CODE      ITH_GROUP_DESC     COMBINED  \n",
       "0                  1  ΣΤΑΦΙΔΑ ΣΟΥΛΤΑΝΙΝΑ      8_2_1_1  \n",
       "2                  2       ΣΤΑΦΙΔΑ ΜΑΥΡΗ      8_2_1_2  \n",
       "4                  4      ΣΤΑΦΥΛΙ GOLDEN      8_2_1_4  \n",
       "5                  5   ΔΑΜΑΣΚΗΝΑ ΑΠΥΡΗΝΑ      8_2_1_5  \n",
       "6                  7            ΒΕΡΥΚΟΚΑ      8_2_1_7  \n",
       "...              ...                 ...          ...  \n",
       "39065              1             GRANOLA     35_1_5_1  \n",
       "39071             13               ZANAE  22_21_11_13  \n",
       "39078              7             CONDITO   22_20_21_7  \n",
       "39079              5           ΦΟΥΝΤΟΥΚΙ    31_21_4_5  \n",
       "39080              6            ΚΑΡΑΜΕΛΑ    31_21_4_6  \n",
       "\n",
       "[10195 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert the column to string and remove leading zeros for numbers less than 9\n",
    "df_item_tree['ITH_GROUP_CODE'] = df_item_tree['ITH_GROUP_CODE'].astype(str).apply(lambda x: x.lstrip('0'))\n",
    "\n",
    "df_item_tree['COMBINED'] = df_item_tree['ITH_SECTION_CODE'].astype(str)+ '_' + df_item_tree['ITH_DEPT_CODE'].astype(str) + '_' + df_item_tree['ITH_CATEG_CODE'].astype(str)+ '_' + df_item_tree['ITH_GROUP_CODE'].astype(str)\n",
    "df_item_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29871b0d-e4ff-46ca-9895-0df319ba94ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents consequents  antecedent support  consequent support   support  \\\n",
      "0        (720)      (3258)            0.078597            0.017753  0.011172   \n",
      "1       (3258)       (720)            0.017753            0.078597  0.011172   \n",
      "2        (365)       (319)            0.086645            0.082352  0.016870   \n",
      "3        (319)       (365)            0.082352            0.086645  0.016870   \n",
      "4        (720)       (365)            0.078597            0.086645  0.010260   \n",
      "5        (365)       (720)            0.086645            0.078597  0.010260   \n",
      "6        (365)       (294)            0.086645            0.050817  0.018033   \n",
      "7        (294)       (365)            0.050817            0.086645  0.018033   \n",
      "8        (387)       (294)            0.059008            0.050817  0.011487   \n",
      "9        (294)       (387)            0.050817            0.059008  0.011487   \n",
      "10      (1000)      (1003)            0.050499            0.040979  0.011990   \n",
      "11      (1003)      (1000)            0.040979            0.050499  0.011990   \n",
      "12       (292)       (365)            0.037166            0.086645  0.011119   \n",
      "13       (365)       (292)            0.086645            0.037166  0.011119   \n",
      "14       (292)       (294)            0.037166            0.050817  0.010727   \n",
      "15       (294)       (292)            0.050817            0.037166  0.010727   \n",
      "16       (720)      (3276)            0.078597            0.040796  0.020422   \n",
      "17      (3276)       (720)            0.040796            0.078597  0.020422   \n",
      "18       (720)      (2603)            0.078597            0.054308  0.016208   \n",
      "19      (2603)       (720)            0.054308            0.078597  0.016208   \n",
      "20       (387)       (365)            0.059008            0.086645  0.030362   \n",
      "21       (365)       (387)            0.086645            0.059008  0.030362   \n",
      "22       (387)       (319)            0.059008            0.082352  0.012288   \n",
      "23       (319)       (387)            0.082352            0.059008  0.012288   \n",
      "\n",
      "    confidence      lift  leverage  conviction  zhangs_metric  \\\n",
      "0     0.142144  8.006698  0.009777    1.145002       0.949752   \n",
      "1     0.629299  8.006698  0.009777    2.485572       0.890921   \n",
      "2     0.194700  2.364239  0.009734    1.139510       0.631771   \n",
      "3     0.204850  2.364239  0.009734    1.148657       0.628815   \n",
      "4     0.130540  1.506600  0.003450    1.050485       0.364937   \n",
      "5     0.118414  1.506600  0.003450    1.045165       0.368153   \n",
      "6     0.208127  4.095599  0.013630    1.198655       0.827538   \n",
      "7     0.354864  4.095599  0.013630    1.415755       0.796301   \n",
      "8     0.194669  3.830770  0.008488    1.178624       0.785294   \n",
      "9     0.226045  3.830770  0.008488    1.215823       0.778518   \n",
      "10    0.237436  5.794148  0.009921    1.257627       0.871417   \n",
      "11    0.292597  5.794148  0.009921    1.342235       0.862767   \n",
      "12    0.299172  3.452845  0.007899    1.303251       0.737805   \n",
      "13    0.128327  3.452845  0.007899    1.104582       0.777774   \n",
      "14    0.288619  5.679550  0.008838    1.334281       0.855734   \n",
      "15    0.211084  5.679550  0.008838    1.220452       0.868041   \n",
      "16    0.259831  6.369026  0.017215    1.295926       0.914898   \n",
      "17    0.500584  6.369026  0.017215    1.844961       0.878843   \n",
      "18    0.206212  3.797116  0.011939    1.191367       0.799478   \n",
      "19    0.298440  3.797116  0.011939    1.313364       0.778945   \n",
      "20    0.514544  5.938527  0.025249    1.881439       0.883756   \n",
      "21    0.350419  5.938527  0.025249    1.448613       0.910498   \n",
      "22    0.208242  2.528687  0.007429    1.159001       0.642447   \n",
      "23    0.149212  2.528687  0.007429    1.106024       0.658791   \n",
      "\n",
      "   retrieved_consequents_combined retrieved_antecedents_combined  \\\n",
      "0                       [6_1_1_1]                      [1_1_4_3]   \n",
      "1                       [1_1_4_3]                      [6_1_1_1]   \n",
      "2                     [15_1_24_1]                    [15_3_13_1]   \n",
      "3                     [15_3_13_1]                    [15_1_24_1]   \n",
      "4                     [15_3_13_1]                      [1_1_4_3]   \n",
      "5                       [1_1_4_3]                    [15_3_13_1]   \n",
      "6                     [15_12_2_1]                    [15_3_13_1]   \n",
      "7                     [15_3_13_1]                    [15_12_2_1]   \n",
      "8                     [15_12_2_1]                    [15_3_18_1]   \n",
      "9                     [15_3_18_1]                    [15_12_2_1]   \n",
      "10                    [23_30_2_2]                    [23_30_1_2]   \n",
      "11                    [23_30_1_2]                    [23_30_2_2]   \n",
      "12                    [15_3_13_1]                    [15_12_1_1]   \n",
      "13                    [15_12_1_1]                    [15_3_13_1]   \n",
      "14                    [15_12_2_1]                    [15_12_1_1]   \n",
      "15                    [15_12_1_1]                    [15_12_2_1]   \n",
      "16                      [6_1_3_2]                      [1_1_4_3]   \n",
      "17                      [1_1_4_3]                      [6_1_3_2]   \n",
      "18                    [49_1_1_11]                      [1_1_4_3]   \n",
      "19                      [1_1_4_3]                    [49_1_1_11]   \n",
      "20                    [15_3_13_1]                    [15_3_18_1]   \n",
      "21                    [15_3_18_1]                    [15_3_13_1]   \n",
      "22                    [15_1_24_1]                    [15_3_18_1]   \n",
      "23                    [15_3_18_1]                    [15_1_24_1]   \n",
      "\n",
      "                            product_names_antecedents  \\\n",
      "0     ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
      "1              ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΒΡΑΣΤΑ, ΠΑΡΙΖΑ   \n",
      "2           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "3         MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.   \n",
      "4     ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
      "5           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "6           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "7   MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...   \n",
      "8         MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
      "9   MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...   \n",
      "10  ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...   \n",
      "11  ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...   \n",
      "12  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...   \n",
      "13          MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "14  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...   \n",
      "15  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...   \n",
      "16    ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
      "17        ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ   \n",
      "18    ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
      "19          ΑΡΤΟΣΚΕΥΑΣΜΑΤΑ, ΨΩΜΙ ΣΥΣΚ/ΝΟ, ΤΟΣΤ, ΦΟΡΜΑ   \n",
      "20        MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
      "21          MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "22        MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
      "23        MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.   \n",
      "\n",
      "                            product_names_consequents  \n",
      "0              ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΒΡΑΣΤΑ, ΠΑΡΙΖΑ  \n",
      "1     ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
      "2         MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.  \n",
      "3           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "4           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "5     ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
      "6   MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...  \n",
      "7           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "8   MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...  \n",
      "9         MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n",
      "10  ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...  \n",
      "11  ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...  \n",
      "12          MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "13  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...  \n",
      "14  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...  \n",
      "15  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...  \n",
      "16        ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ  \n",
      "17    ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
      "18          ΑΡΤΟΣΚΕΥΑΣΜΑΤΑ, ΨΩΜΙ ΣΥΣΚ/ΝΟ, ΤΟΣΤ, ΦΟΡΜΑ  \n",
      "19    ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
      "20          MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "21        MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n",
      "22        MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.  \n",
      "23        MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to map IDs to names\n",
    "def map_ids_to_names(ids_set):\n",
    "    names = []\n",
    "    for product_id in ids_set:\n",
    "        row = df_item_tree[df_item_tree['COMBINED'] == product_id]\n",
    "        if not row.empty:\n",
    "            name = ', '.join(row[['ITH_SECTION_DESC', 'ITH_DEPT_DESC', 'ITH_CATEG_DESC', 'ITH_GROUP_DESC']].values[0])\n",
    "            names.append(name)\n",
    "        else:\n",
    "            names.append('ID not found')\n",
    "    return ', '.join(names)\n",
    "\n",
    "# Apply the function to create a new column with names from IDs\n",
    "rules_df['product_names_consequents'] = rules_df['retrieved_consequents_combined'].apply(map_ids_to_names)\n",
    "\n",
    "print(rules_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6398bd4a-2d0a-448c-90cf-deab4ae9798c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "rules_df.to_csv('finalrules.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "276c11a5-b101-4a02-a9af-adbfd6d7daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      support     itemsets      retrieved_itemsets  \\\n",
      "0    0.086645        (365)             [15_3_13_1]   \n",
      "1    0.072977       (2717)            [51_11_10_3]   \n",
      "2    0.055892        (444)              [15_6_1_2]   \n",
      "3    0.046473        (577)              [17_1_2_2]   \n",
      "4    0.036788       (3814)            [81_31_14_1]   \n",
      "..        ...          ...                     ...   \n",
      "203  0.010727   (292, 294)  [15_12_1_1, 15_12_2_1]   \n",
      "204  0.020422  (720, 3276)      [1_1_4_3, 6_1_3_2]   \n",
      "205  0.016208  (720, 2603)    [1_1_4_3, 49_1_1_11]   \n",
      "206  0.030362   (387, 365)  [15_3_18_1, 15_3_13_1]   \n",
      "207  0.012288   (387, 319)  [15_3_18_1, 15_1_24_1]   \n",
      "\n",
      "                                product_names_itemsets  \n",
      "0            MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "1         ΜΗ ΑΛΚΟΟΛΟΥΧΑ, ΝΕΡΑ, ΦΥΣΙΚΑ ΝΕΡΑ, 500ml ΝΕΡΑ  \n",
      "2    MANABIKH, ΕΤΟΙΜΕΣ ΣΑΛΑΤΕΣ, ΕΓΧΩΡΙΕΣ ΕΤΟΙΜΕΣ ΣΑ...  \n",
      "3    ΝΩΠΟ ΚΡΕΑΣ, ΛΟΥΚΑΝΙΚΑ, ΣΥΣΚΕΥΑΣΜΕΝΑ-ΤΥΠΟΠΟΙΗΜΕ...  \n",
      "4    EIΔΗ ΠΕΡΙΠΟΙΗΣΗΣ-ΚΑΘΑΡΙΟΤΗΤΑΣ, ΠΡΟΣΩΠΙΚΗ ΠΕΡΙΠ...  \n",
      "..                                                 ...  \n",
      "203  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...  \n",
      "204  ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUD...  \n",
      "205  ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUD...  \n",
      "206  MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ, M...  \n",
      "207  MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ, M...  \n",
      "\n",
      "[208 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to map IDs to names\n",
    "def map_ids_to_names(ids_set):\n",
    "    names = []\n",
    "    for product_id in ids_set:\n",
    "        row = df_item_tree[df_item_tree['COMBINED'] == product_id]\n",
    "        if not row.empty:\n",
    "            name = ', '.join(row[['ITH_SECTION_DESC', 'ITH_DEPT_DESC', 'ITH_CATEG_DESC', 'ITH_GROUP_DESC']].values[0])\n",
    "            names.append(name)\n",
    "        else:\n",
    "            names.append('ID not found')\n",
    "    return ', '.join(names)\n",
    "\n",
    "# Apply the function to create a new column with names from IDs\n",
    "frequent_itemsets_df['product_names_itemsets'] = frequent_itemsets_df['retrieved_itemsets'].apply(map_ids_to_names)\n",
    "\n",
    "print(frequent_itemsets_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69072f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frequent_itemsets_df.to_csv('final_frequentitemsets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e88948cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_names_antecedents</th>\n",
       "      <th>product_names_consequents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "      <td>ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΒΡΑΣΤΑ, ΠΑΡΙΖΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΒΡΑΣΤΑ, ΠΑΡΙΖΑ</td>\n",
       "      <td>ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.</td>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...</td>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...</td>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...</td>\n",
       "      <td>ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...</td>\n",
       "      <td>ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...</td>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...</td>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...</td>\n",
       "      <td>MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "      <td>ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ</td>\n",
       "      <td>ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "      <td>ΑΡΤΟΣΚΕΥΑΣΜΑΤΑ, ΨΩΜΙ ΣΥΣΚ/ΝΟ, ΤΟΣΤ, ΦΟΡΜΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ΑΡΤΟΣΚΕΥΑΣΜΑΤΑ, ΨΩΜΙ ΣΥΣΚ/ΝΟ, ΤΟΣΤ, ΦΟΡΜΑ</td>\n",
       "      <td>ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "      <td>MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.</td>\n",
       "      <td>MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            product_names_antecedents  \\\n",
       "0     ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
       "1              ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΒΡΑΣΤΑ, ΠΑΡΙΖΑ   \n",
       "2           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "3         MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.   \n",
       "4     ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
       "5           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "6           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "7   MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...   \n",
       "8         MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
       "9   MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...   \n",
       "10  ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...   \n",
       "11  ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...   \n",
       "12  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...   \n",
       "13          MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "14  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...   \n",
       "15  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...   \n",
       "16    ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
       "17        ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ   \n",
       "18    ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
       "19          ΑΡΤΟΣΚΕΥΑΣΜΑΤΑ, ΨΩΜΙ ΣΥΣΚ/ΝΟ, ΤΟΣΤ, ΦΟΡΜΑ   \n",
       "20        MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
       "21          MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "22        MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
       "23        MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.   \n",
       "\n",
       "                            product_names_consequents  \n",
       "0              ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΒΡΑΣΤΑ, ΠΑΡΙΖΑ  \n",
       "1     ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
       "2         MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.  \n",
       "3           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "4           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "5     ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
       "6   MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...  \n",
       "7           MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "8   MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...  \n",
       "9         MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n",
       "10  ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...  \n",
       "11  ΖΥΜΑΡΙΚΑ, ΖΥΜΑΡΙΚΑ ΠΑΡΑΓΩΜΕΝΑ-STANDARD, ΖΥΜΑΡΙ...  \n",
       "12          MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "13  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...  \n",
       "14  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΚΡΕΜΜΥΔΙΑ,...  \n",
       "15  MANABIKH, ΠΑΤΑΤΕΣ-ΚΡΕΜΜΥΔΙΑ-ΣΚΟΡΔΑ, ΠΑΤΑΤΕΣ, Π...  \n",
       "16        ΑΛΛΑΝΤΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ  \n",
       "17    ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
       "18          ΑΡΤΟΣΚΕΥΑΣΜΑΤΑ, ΨΩΜΙ ΣΥΣΚ/ΝΟ, ΤΟΣΤ, ΦΟΡΜΑ  \n",
       "19    ΤΥΡΟΚΟΜΙΚΑ, ΧΥΜΑ-ΠΑΓΚΟΥ, ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
       "20          MANABIKH, ΛΑΧΑΝΙΚΑ, ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "21        MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n",
       "22        MANABIKH, ΦΡΟΥΤΑ, ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.  \n",
       "23        MANABIKH, ΛΑΧΑΝΙΚΑ, ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load specific columns from the CSV file\n",
    "columns_to_load = ['product_names_antecedents', 'product_names_consequents']  # Add the column names you want to load\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your actual file\n",
    "filtered_df = pd.read_csv('finalrules.csv', usecols=columns_to_load)\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a03db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    product_names_antecedents  \\\n",
      "0                      ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
      "1                              ΒΡΑΣΤΑ, ΠΑΡΙΖΑ   \n",
      "2                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "3                   ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.   \n",
      "4                      ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
      "5                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "6                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "7                ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ   \n",
      "8                     ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
      "9                ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ   \n",
      "10  ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ, 301-700G ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ   \n",
      "11  ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ, 301-700G ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ   \n",
      "12                  ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ   \n",
      "13                      ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "14                  ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ   \n",
      "15               ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ   \n",
      "16                     ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
      "17                        ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ   \n",
      "18                     ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
      "19                                ΤΟΣΤ, ΦΟΡΜΑ   \n",
      "20                    ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
      "21                      ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
      "22                    ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
      "23                  ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.   \n",
      "\n",
      "                    product_names_consequents  \n",
      "0                              ΒΡΑΣΤΑ, ΠΑΡΙΖΑ  \n",
      "1                      ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
      "2                   ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.  \n",
      "3                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "4                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "5                      ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
      "6                ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ  \n",
      "7                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "8                ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ  \n",
      "9                     ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n",
      "10  ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ, 301-700G ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ  \n",
      "11  ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ, 301-700G ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ  \n",
      "12                      ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "13                  ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ  \n",
      "14               ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ  \n",
      "15                  ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ  \n",
      "16                        ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ  \n",
      "17                     ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
      "18                                ΤΟΣΤ, ΦΟΡΜΑ  \n",
      "19                     ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
      "20                      ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
      "21                    ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n",
      "22                  ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.  \n",
      "23                    ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to process the columns\n",
    "def process_columns(row):\n",
    "    split_row = row.split(',', 2)  # Split at the second comma\n",
    "    processed_row = split_row[2].strip() if len(split_row) > 2 else row  # Keep everything after the second comma\n",
    "    return processed_row\n",
    "\n",
    "# Apply the function to the specified columns\n",
    "columns_to_process = ['product_names_antecedents', 'product_names_consequents']\n",
    "for col in columns_to_process:\n",
    "    filtered_df[col] = filtered_df[col].apply(process_columns)\n",
    "\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d5a2727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_names_antecedents</th>\n",
       "      <th>product_names_consequents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "      <td>ΒΡΑΣΤΑ, ΠΑΡΙΖΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ΒΡΑΣΤΑ, ΠΑΡΙΖΑ</td>\n",
       "      <td>ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.</td>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ</td>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "      <td>ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ</td>\n",
       "      <td>ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ, 301-700G ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ</td>\n",
       "      <td>ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ, 301-700G ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ, 301-700G ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ</td>\n",
       "      <td>ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ, 301-700G ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ</td>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ</td>\n",
       "      <td>ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ</td>\n",
       "      <td>ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "      <td>ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ</td>\n",
       "      <td>ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "      <td>ΤΟΣΤ, ΦΟΡΜΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ΤΟΣΤ, ΦΟΡΜΑ</td>\n",
       "      <td>ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.</td>\n",
       "      <td>ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "      <td>ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.</td>\n",
       "      <td>ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    product_names_antecedents  \\\n",
       "0                      ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
       "1                              ΒΡΑΣΤΑ, ΠΑΡΙΖΑ   \n",
       "2                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "3                   ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.   \n",
       "4                      ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
       "5                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "6                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "7                ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ   \n",
       "8                     ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
       "9                ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ   \n",
       "10  ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ, 301-700G ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ   \n",
       "11  ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ, 301-700G ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ   \n",
       "12                  ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ   \n",
       "13                      ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "14                  ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ   \n",
       "15               ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ   \n",
       "16                     ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
       "17                        ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ   \n",
       "18                     ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA   \n",
       "19                                ΤΟΣΤ, ΦΟΡΜΑ   \n",
       "20                    ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
       "21                      ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.   \n",
       "22                    ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ   \n",
       "23                  ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.   \n",
       "\n",
       "                    product_names_consequents  \n",
       "0                              ΒΡΑΣΤΑ, ΠΑΡΙΖΑ  \n",
       "1                      ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
       "2                   ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.  \n",
       "3                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "4                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "5                      ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
       "6                ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ  \n",
       "7                       ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "8                ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ  \n",
       "9                     ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n",
       "10  ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ, 301-700G ΖΥΜΑΡΙΚΑ ΠΑΣΤΕΣ  \n",
       "11  ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ, 301-700G ΖΥΜΑΡΙΚΑ ΜΑΚΡΙΑ  \n",
       "12                      ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "13                  ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ  \n",
       "14               ΚΡΕΜΜΥΔΙΑ, ΚΡΕΜΜΥΔΙΑ ΕΓΧΩΡΙΑ  \n",
       "15                  ΠΑΤΑΤΕΣ, ΠΑΤΑΤΕΣ ΕΓΧΩΡΙΕΣ  \n",
       "16                        ΚΑΠΝΙΣΤΑ, ΓΑΛΟΠΟΥΛΑ  \n",
       "17                     ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
       "18                                ΤΟΣΤ, ΦΟΡΜΑ  \n",
       "19                     ΗΜΙΣΚΛΗΡΑ ΤΥΡΙΑ, GOUDA  \n",
       "20                      ΤΟΜΑΤΕΣ, ΤΟΜΑΤΕΣ ΕΓΧ.  \n",
       "21                    ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  \n",
       "22                  ΜΠΑΝΑΝΕΣ, ΜΠΑΝΑΝΕΣ ΕΙΣΑΓ.  \n",
       "23                    ΑΓΓΟΥΡΙΑ, ΑΓΓΟΥΡΙΑ ΧΥΜΑ  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc90dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
